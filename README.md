# Interpretable_ML_Resources

This repository is devoted to curating and organizing resources used to increase the ability of humans to understand and explain models. 

It prioritizes quality over quantity, limiting each subsection to the top 5-10 links we've found so far.  It thus doesn't try to be exhaustive.  For exhaustive aggregations, see the resources at the bottom of this page and the "overflow.md" file.

# General XAI Packages

## XAI Dashboards and Suites  in Python
* iModel - https://github.com/csinva/imodels -  "Python package for concise, transparent, and accurate predictive modeling. All sklearn-compatible and easy to use."
* InterpretML - https://github.com/interpretml/interpret
* Explainer Dashboard - https://github.com/oegedijk/explainerdashboard
* Alibi - https://github.com/SeldonIO/alibi
* AI Explainability 360 - https://github.com/Trusted-AI/AIX360

### Specific XAI Packages
* DiCE - Diverse Counterfactual Explanations - https://github.com/interpretml/DiCE
* Shapash - A Shapley Explainer Dashboard - https://shapash.readthedocs.io/en/latest/

## XAI Packages in R
* https://github.com/ModelOriented/DrWhy
* 

# White Box Models (Traditionally Explainable Models)

## Linear Models 
* **Statsmodels** - Great statistical output for regression models -  https://www.statsmodels.org/stable/index.html


## Sparse Models and Regularization:

Sparse models tend to be more interpretable and explainable because they reduce the complexity of models.
**Sparsity and Regularization** - 

# Glass Box Models (Newer Explainable Models)

## Explainable Tree Models

# Model Agnostic Tools

# Black Box Model Explainability

## Explainable Deep Learning Models

* **Tensorboard What-if Tool** - https://www.tensorflow.org/tensorboard/what_if_tool - "The What-If Tool (WIT) provides an easy-to-use interface for expanding understanding of black-box classification and regression ML models. With the plugin, you can perform inference on a large set of examples and immediately visualize the results in a variety of ways. Additionally, examples can be edited manually or programmatically and re-run through the model in order to see the results of the changes. It contains tooling for investigating model performance and fairness over subsets of a dataset."


### NLP Explainability
* **LIT - Language Interpretability Tool** - https://github.com/pair-code/lit - "LIT is built to answer questions such as: What kind of examples does my model perform poorly on?
Why did my model make this prediction? Can this prediction be attributed to adversarial behavior, or to undesirable priors in the training set?  Does my model behave consistently if I change things like textual style, verb tense, or pronoun gender?"

# Interpretable Causal Inference + Counterfactuals

# Feature Selection and Interpretability

# Books

* **Interpretable Machine Learning** - Serg Masis
* **XAI Stories** - Free Online Book - https://pbiecek.github.io/xai_stories/

# Other Aggregations of ML Interpretability Resources

* **H2o AI** https://github.com/h2oai/mli-resources
* "Interesting Resources" - Very nice article summaries https://github.com/pbiecek/xai_resources
* **Awesome-Xai** - https://github.com/altamiracorp/awesome-xai
* **Another Awesome XAI Mostly Papers** - https://github.com/lopusz/awesome-interpretable-machine-learning
* https://github.com/pbiecek/xai_resources
* **Yet Another awesome XAI - Alphabetical Order** - https://github.com/jphall663/awesome-machine-learning-interpretability
